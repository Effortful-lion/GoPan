# 开发一：完成基本的文件上传服务
1. 返回文件上传页面
2. 选取本地文件，form上传
3. 云端接收并保存到本地文件系统
4. 云端更新文件元信息集合
5. 删除、查询功能
6. 下载功能（加载并返回）
7. 文件信息存储在内存中，重启后丢失（问题）

# 开发二：基于mysql存储文件元信息
1. 为什么使用mysql？
   1. 数据量不大、用户数也不大
   2. 小、稳定、社区活跃
   3. 在当前项目场景下，mysql足够进行文件元信息的存储
2. 使用mysql主从集群
   1. 实现读写分离：主数据库负责写请求，从数据库负责读请求。
   2. 提高性能：从数据库可以处理更多的读请求，从而提高系统的整体性能。
   3. 同步数据，提高数据一致性
   4. 故障回复：主数据库发生故障时，可以切换到从数据库，保证系统的可用性。
3. 分库分表
   1. 水平分库：将数据分散到多个数据库中，每个数据库存储一部分数据。
   2. 水平分表：将数据分散到多个表中，每个表存储一部分数据。
   3. 垂直分表：将数据不同字段分散到不同的表中，每个表存储一部分字段的数据。
   4. 举例：比如在这里怎么分表
      假设分成256张表：
      按照文件sha1值的后两位切分，后两位每位是0-15，因此从 00 到 ff，共256张表。
   5. 我们这里先用简单的单表

# 开发三：账号系统
1. 注册、登录
2. 用户登录session/token（这里用token）
3. 用户资源隔离
4. 云端资源共享管理

# 开发四：文件秒传
1. 云端存储文件哈希值
2. 客户端上传文件时，先计算文件哈希值（如果没有计算，那么就不会触发秒传）
3. 对于其中处理相同文件的逻辑：
   1. 允许不同用户上传相同文件
   2. 先上传完成的先落库
   3. 对于之后上传的相同的文件，只更新用户文件表就可以了，文件通过哈希值共享
4. hash算法的应用场景和区别：crc、md5、sha1.
   1. 长度、大小：crc 16位，md5 128位，sha1 160位
   2. 速度：crc 最快，md5 次之，sha1 最慢
   3. 碰撞概率：crc 极低，md5 较低，sha1 极低
   4. 应用场景：crc 用于校验数据传输，md5 用于校验数据完整性，sha1 用于校验数据完整性和防篡改

# 开发五：断点续传和分块上传
1. 小文件不适合分块上次
2. 可以并行上传分块，且可以无序传输
3. 分块上传可以极大提高文件上传的效率，尤其是对于大文件。
4. 断点续传：减少传输失败后的重试次数，提高上传效率。（部分已经传输成功了，不需要全部重传）
5. 分块上传流程：
   服务端（括号中：客户端）：
      1. 初始化分块信息（客户端从接口中获取到 上传的唯一id 和 分块的规则）
      2. 上传分块
      3. 通知上传成功
      4. 取消上传分块
      5. 查看分块上传的整体进度
6. 测试断点续传：
   1. 调接口1：就是将分块上传中断（取消分块上传）
   2. 调接口2：获取分块上传进度，得到 百分比 + 还需要上传的分块列表

# 开发六：阿里云oss存储
1. 阿里云oss存储：对象存储服务，用于存储和管理非结构化数据，如图片、视频、音频、文档等。
2. 为什么使用阿里云oss存储：
   1. 可靠性：服务可用、数据持久
   2. 安全性：资源隔离存储、访问鉴权
   3. 易用性：restfulapi接口、SDK
   4. 处理能力：海量规模、图片处理、音视频转码(各种清晰度)...
3. 注意：配置子用户，授权oss服务权限
4. 很多问题可能是网络的问题（注意oss私有下，公网访问和内网访问的配置不同）

# 开发七：Rabbitmq实现异步转移服务
1. 接入消息队列后的上传步骤：
   1. 客户端上传请求 到 服务端上传服务
   2. 服务端上传服务 立刻响应 客户端
   3. 服务端将文件 临时保存到本地服务器，将本地临时路径保存到mysql中（防止在响应后和真正上传前，用户发送请求时，可以直接访问服务器上的临时文件）
   4. 服务端另外开一个协程 监听消息队列的上传任务队列
   5. 接收任务，读取临时文件
   6. 执行真正的上传逻辑
   7. 上传成功后，删除临时文件，更新真实文件存储路径
2. 组件：
   Exchange：消息交换机，决定消息路由规则，可转发到多个队列（消息接收和转发）
   Queue：消息载体，存储待消费消息（消息存储）
   Binding：绑定动作，建立交换机和队列的路由规则（路由规则映射关系）通过 Binding Key 定义路由规则 
   Binding Key：绑定键，用于定义消息路由规则（定义路由规则）
   Routing Key：路由键，生产者发布时指定，决定消息路由目标（路由key-->指导交换机 向特定的队列发送消息）
   Channel：消息通道，客户端与RabbitMQ建立的连接管道（消息投放对象）
   // 以下是用户需要实现的部分
   Producer：消息生产者（同Publisher）
   Consumer：消息消费者，通过长连接持续接收消息
3. 工作模式：
   1. fanout：广播模式，将消息路由到所有绑定的队列
   2. direct：定向模式，将消息一对一路由到指定的队列（Routing Key--Binding Key 1:1）
   3. Topic ：通配符模式，将消息路由到符合指定路由规则的队列（（具体的路由键）Routing Key--（支持通配符）Binding Key m:n）
   4. Headers：头信息模式，请求头和消息头匹配时，才能接收消息

# 开发八：微服务化
内容：
1. 根据api将功能划分开，进行服务拆分，之后各个服务单独进行proto文件编写、service的编写
2. 网关层代码的改写
3. 集成etcd等服务注册中心
4. 进行服务注册
5. 测试前，相关服务之间分别进行rpc客户端的初始化
6. 启动时，注意：各个服务之间有依赖关系（网关是依赖各个服务的，所以网关服务最后开，其他的服务也一样，被依赖的服务先开）

重点：
1. 文件秒传原理
   1. 客户端上传文件时，先计算文件的哈希值，然后上传。
   2. 服务端查询共享资源（数据库），如果存在相同的哈希值，直接响应上传成功；如果不存在，就响应无法秒传，转移到普通上传接口。
   3. 更新数据库。因为我们的共享资源，他是通过数据和逻辑分离的方式，构建了 files 表 和 user-file 表，通过单独的files表存储共享的资源。通过 user-file 表来存储具体用户上传的文件

2. 分块上传和断点续传原理
   分块上传：
   1. 客户端在上传前先进行文件的哈希计算和大小计算。向服务端发起请求。
   2. 服务端接收请求信息后，确定分块的方式（每块的大小）。生成唯一的分块请求id，然后将文件元信息、分块信息和分块请求id存入redis，然后再响应给客户端。
   3. 客户端根据服务端的要求进行固定大小的分块操作。然后再依次（多次请求）请求发送分块数据，请求参数携带分块序号和分块请求id
   4. 服务端接收临时分块数据保存在本地文件系统中，并更新分块的信息（每块上传后，都会记录到redis中）
   5. 客户端全部上传之后，向服务端发起合并请求通知。（请求携带分块请求id、文件哈希）
   6. 服务端接收到请求后，根据请求id从redis中获取文件元信息，比较文件哈希值是否一致，如果不一致就查询redis中记录的分块信息，查询缺少的索引块列表。响应回客户端。
   7. 客户端接收到缺失响应后，会重新上传缺失的分块数据。
   8. 等到服务端分块数据齐全后，服务端将会在本地文件系统中读取指定请求id的分块数据，先排序后合并到一个文件中，存储到本地或者云存储。删除临时分块文件。
   9. 分块完成！

   断点续传：（总的来讲：）
   1. 上传前信息获取：客户端上传前获取已传文件信息（如文件名、哈希值）。
   2. 确定未传范围：客户端自查已传数据，通过 Range 头向服务端发送未传数据范围。
   3. 服务端响应：服务端依请求 ID 获取文件元信息，解析 Range 头，用 Content-Range 头返回对应文件范围数据。
   4. 更新本地文件：客户端据 Content-Range 头更新本地文件指定范围。
   5. 继续上传分块：客户端重复上传剩余分块。
   6. 发送合并请求：全部分块上传完成，客户端向服务端发合并请求。
   7. 服务端合并文件：服务端按请求 ID 获取元信息，合并分块数据。
   8. 清理临时文件：合并完成，服务端删除临时分块文件。
   9. 流程结束：断点续传完成。

3. rabbitmq工作原理和转发模式
   1. 生产者：生产者 发送信息 到 exchange
   2. exchange：根据路由key（routing key），将信息转发到对应的队列
   3. 队列：队列 接收信息 并存储信息
   4. 消费者：消费信息 从指定队列中消费

   转发模式：
   1. 广播（一对多）、定向（一对一）、通配符（一对多：routing key 支持通配符，可以转发给多个满足条件的队列、heads（头信息模式）模式：通过请求头和消息头匹配时发送）

4. 文件异步转移中，生产者逻辑？消费者逻辑？
   生产者：（生产消息：通过 交换机、routing key 发送消息）
   1. 初始化mq连接，创建channel
   2. 创建交换机（exchange）（可选/消费者也可以创建）
   3. 发送消息
   消费者：（消费消息：从队列中获取消息）
   1. 通过channel新增交换机（exchange）
   2. 新增队列（queue）
   3. 绑定交换机和队列（binding key）
   4. 消费消息（启动一个协程，循环接收消息）
   5. 可以将处理失败的消息放到一个错误队列中，等待再次消费或者丢弃

5. 直传阿里oss的方案
   1. 客户端通过请求，获取阿里oss直传的url（url是服务端经过签名的：oss.New(cfg.OSSEndpoint, cfg.OSSAccessKeyID, cfg.OSSAccessKeySecret).Bucket().SignURL(objectName, oss.HTTPGet, expires)）
   2. 客户端将文件上传到阿里oss（直传）
   3. 服务端将文件信息更新到数据库（文件表）

6. 分布式存储一致性：解决多存储后端间的数据一致性问题，确保文件元数据与实际存储状态同步，保证系统可靠性。

项目通过**异步文件转移机制**实现了分布式存储一致性：

1. **文件上传时**：先保存到本地临时位置，立即更新数据库元信息（临时路径），然后通过RabbitMQ消息队列异步转移到OSS存储。

2. **转移完成后**：自动更新数据库中的文件路径为OSS真实路径，确保元数据与实际存储状态同步。

3. **多存储支持**：通过统一的DBProxy服务管理文件元信息，支持本地、OSS、Ceph等多种存储后端，保证路径一致性。

4. **可靠性保证**：使用持久化消息队列和断线重连机制，确保异步转移的可靠性。

这样既保证了上传响应速度，又确保了文件元数据与实际存储状态的一致性。

7. Ceph存储方案：

**定义：** Ceph 是一个广泛应用、高可用性、可扩展的分布式存储系统。它提供对象、块和文件三种类型的存储，支持 RESTful 和 S3 访问协议。Ceph 的优点在于高可用性、数据安全、容错能力和低成本等方面。

**核心功能**: 解决数据分布式存储问题，相比其他存储系统能充分利用存储节点的计算能力

**技术优势:**
通过哈希算法自动计算数据存储位置，实现数据均匀分布
避免单点故障，支持无限节点扩展
可基于私有云构建分布式存储系统




